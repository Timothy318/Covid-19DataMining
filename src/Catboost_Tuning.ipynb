{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585bda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, confusion_matrix,\\\n",
    " ConfusionMatrixDisplay, recall_score, accuracy_score, f1_score, classification_report, make_scorer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee234fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file: ../data/cases_train_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "def process_data(name):\n",
    "    file = r'../data/' + name + '.csv'\n",
    "    print(\"processing file: {}\".format(file))\n",
    "    file = pd.read_csv(r'../data/cases_train_preprocessed.csv',dtype=object)\n",
    "    file.drop(columns=['land','Last_Update','province','country'],inplace=True)\n",
    "    file['source'] = file['source'].fillna(value='')\n",
    "    return file\n",
    "file = process_data(\"cases_train_preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c25320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test split for model evaluation\n",
    "def catboost_data(file):\n",
    "    cat_feature=['sex','source','age_range_ind','age_range']\n",
    "    text_feature = ['additional_information']\n",
    "\n",
    "    df_tr, df_va = train_test_split(file, test_size=0.2, random_state = 1)\n",
    "\n",
    "    df_tr_x = df_tr.drop(columns=\"outcome\")\n",
    "    df_tr_y = df_tr['outcome']\n",
    "\n",
    "    df_tr_data = Pool(data = df_tr_x,\n",
    "                   label = df_tr_y,\n",
    "                   cat_features = cat_feature, \n",
    "                   text_features=text_feature)\n",
    "\n",
    "    df_va_x = df_va.drop(columns=\"outcome\")\n",
    "    df_va_y = df_va['outcome']\n",
    "\n",
    "    df_va_data = Pool(data = df_va_x,\n",
    "                   label = df_va_y,\n",
    "                   cat_features = cat_feature, \n",
    "                   text_features=text_feature)\n",
    "    return df_tr_x, df_tr_y, df_va_x, df_va_y\n",
    "tr, tr_y, va, va_y = catboost_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef406d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying possible parameters of catboost\n",
    "grid = {'learning_rate': [0.1, 0.2, 0.3],\n",
    "        'depth': [6, 8, 10, 14, 10],\n",
    "        'l2_leaf_reg': [0.2, 0.4, 0.6],\n",
    "        'n_estimators':[400, 500, 600]\n",
    "       }\n",
    "\n",
    "# Specify catboost parameters\n",
    "cat_feature=['sex','source','age_range_ind','age_range']\n",
    "text_feature = ['additional_information']\n",
    "\n",
    "# Creating required scoring function\n",
    "scorer = {\n",
    "    'f1_macro' : make_scorer(f1_score, average='macro'),\n",
    "    'recall_macro': make_scorer(recall_score , average='macro'),\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'recall_d' : make_scorer(recall_score,average=None,labels=['deceased']),\n",
    "    'f1_d' : make_scorer(f1_score, average=None, labels=['deceased']),\n",
    "}\n",
    "\n",
    "# Creating Catboost model\n",
    "model = CatBoostClassifier( task_type=\"GPU\",\n",
    "                            devices='0:1',\n",
    "                            loss_function='MultiClass',\n",
    "                            auto_class_weights = 'SqrtBalanced',\n",
    "                            cat_features = cat_feature,\n",
    "                            text_features = text_feature)\n",
    "\n",
    "clf_grid = GridSearchCV(estimator=model, param_grid=grid, scoring=scorer, cv= StratifiedKFold(n_splits=5), refit=\"f1_d\", n_jobs=-1)\n",
    "clf = clf_grid.fit(tr, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf84696",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_grid.best_params_)\n",
    "df = pd.DataFrame(clf_grid.cv_results_ )\n",
    "df = df.sort_values(by='rank_test_f1_d')\n",
    "df = df[df.columns.drop(list(df.filter(regex=r'(time)|(std)|(split)|(param_)|(rank)')))]\n",
    "df = df[['params', 'mean_test_f1_d', 'mean_test_recall_d', 'mean_test_accuracy', 'mean_test_recall_macro','mean_test_f1_macro']]\n",
    "df.rename(columns={\"mean_test_f1_macro\": \"Overall F1-Score(Macro)\", \n",
    "                   \"mean_test_recall_macro\": \"Overall Recall(Macro)\",\n",
    "                   \"mean_test_accuracy\": \"Overall Accuracy\",\n",
    "                   \"mean_test_f1_d\": \"F1-Score on Deceased\",\n",
    "                   \"mean_test_recall_d\": \"Recall on Deceased\",\n",
    "                   \"params\": \"Hyperparameters\"\n",
    "                  },inplace=True)\n",
    "df.to_csv('../results/catboost_tuning.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81397c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['hospitalized', 'nonhospitalized','recovered', 'deceased']\n",
    "va_pred = clf.predict(va)\n",
    "ev_va_report = classification_report(va_y, va_pred)\n",
    "ev_va_accuracy = accuracy_score(va_y, va_pred)\n",
    "ev_va_matrix = confusion_matrix(va_y, va_pred,labels=label)\n",
    "print(ev_va_report)\n",
    "ConfusionMatrixDisplay(ev_va_matrix).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab762cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if prediction file is valid\n",
    "# def check_if_file_valid(filename):\n",
    "#     assert filename.endswith('../results/predictions.txt'), 'Incorrect filename'\n",
    "#     f = open(filename).read()\n",
    "#     l = f.split('\\n')\n",
    "#     assert len(l) == 46500, 'Incorrect number of items'\n",
    "#     assert (len(set(l)) == 4), 'Wrong class labels'\n",
    "#     return 'The predictions file is valid'\n",
    "# check_if_file_valid('predictions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916bc56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
